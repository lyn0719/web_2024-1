 4차 산업혁명 시대가 발전함에 따라 인공지능이 활동할 수 있는 영역이 넓어지고 있다. 인공지능이란 인간의 지능을 컴퓨터로 구현하여 지능적 행위를 흉내 낼 수 있도록 한 기술이다. 현대사회에서는 이미 인간의 역할을 대체하고 있는 경우가 늘어나고 있다. 그렇다면 인공지능은 미래에 어떤 사회적 문제를 해결할 수 있을까?
 미래사회에서 해결해야 할 사회적 문제의 예시를 들어보자면, 법률 영역의 판결이나 공공안전과 보안 영역 등 다양한 사회적 문제가 현대사회에서 대두되고 있다. 한 가지 예시를 들어 법률 영역에서의 판결을 어떻게 인공지능이 해결할 수 있겠냐고 묻는다면 인공지능은 인간보다 더 많은 데이터를 학습할 수 있고 인간보다 더 알맞게 분석하여 판결을 내릴 수도 있다. 인공지능에게 법률과 다양한 판례를 학습시키는 것은 인간 스스로 학습하는 것보다 훨씬 정교하고 잘못된 판결을 내릴 일이 적을 확률이 높다.
하지만 그렇다고 해서 인공지능이 내리는 판결을 모두 정확한 판결이라고 정의할 수는 없다. 인공지능이 잘못된 데이터를 학습했을 수도 있고, 학습한 데이터의 양이 부족하여 판단하기 어려운 경우가 생길 수도 있기 때문이다. 그렇다면 데이터로 인한 인공지능의 문제를 해결할 차례가 다가왔다. 위의 법률 영역에서의 판결 사례를 보았듯이 잘못된 데이터를 인공지능에게 학습시켜준다면 인공지능은 올바른 판결을 내릴 수 없다. 이렇듯 사회적 편견이 반영된 부적절한 속성을 사용한 데이터나 데이터의 양이 한쪽으로 치우쳐 균형이 맞지 않는 데이터를 편향된 데이터라고 한다. 데이터 편향성은 인공지능 수행결과에서 편향된 결과를 만들어 내고 인간은 그러한 인공지능의 편향된 결과를 받아들여 편견과 편향이 사회에 존재하는 상황이 초래된다. 데이터 편향성을 줄이는 방법에는 3가지로 구분할 수 있다.
첫 번째, 인공지능의 작동 원리를 이해하여야 한다. 인공지능은 인간의 역사가 담긴 데이터로 학습하기에 인간의 편향성이 포함되어 학습할 수밖에 없다. 우리는 인공지능이 항상 인간의 편향성이 담겨있는 결과를 불러일으킨다는 것을 인지하고 결과를 받아들여야 한다. 두 번째, 다양성을 대표하는 데이터를 수집하고 활용하여야 한다. 인공지능이 학습하는 데이터가 공정성을 위배하지 않도록 편향되지 않은 데이터를 수집하고 비판적 시각으로 데이터를 선별하여 사용해야 한다. 세 번째, 사회적 편견을 만들지 않도록 노력해야 한다. 사회적 다양성을 고려하여 편견이 데이터에 반영되지 않도록 사회 구성원이 노력하여 올바른 데이터가 형성될 수 있도록 해야 한다.
한 가지 다른 이야기를 해보고자 한다. 인공지능 기술이 나날이 성장하고 있는 사회에서 ‘자율주행 자동차’라는 단어를 들어보지 못한 사람은 없을 것이다. 여기서 재밌는 문제 상황을 한 가지 제공할 것인데 이 문제에 대하여 다 같이 고민해보았으면 좋겠다. <자율주행 자동차를 운행하던 중 인명사고가 발생하였다. 인공지능 개발자, 인공지능 사용자, 인공지능 제품 및 서비스 공급자 중 가장 큰 책임이 있다고 생각하는 구성원은 누구인가?> 이 문제에서 어떠한 구성원이 가장 큰 책임이 있는지에 대하여 정답이 있는 것은 아니지만, 작자 본인은 이 문제에 대하여 인공지능 사용자가 가장 큰 책임이 있다고 생각하는 바이다. 그렇게 생각한 이유는 자율주행 자동차를 개발한 인공지능 개발자와 인공지능 제품 및 서비스 공급자는 사용자가 최적으로 제품을 사용할 수 있도록 충분히 인지를 시킨 후 제품을 제공한다고 했을 때, 인공지능 사용자는 아무리 자율주행 자동차가 운전 대부분 상황을 판단한다고 할지라도 올바른 사용을 위하여 주의를 기울여야 하는 게 맞다. 사용자가 운전에 집중하지 않고 잠시 잠을 청하다가 인명사고가 났다면 그것이 개발자와 공급자에게 책임이 있다고 물을 수 있을지 확신할 수 없다. 어떠한 상황 조건인지에 따라 책임을 지는 구성원은 달라질 수 있지만, 기본적으로 사용자는 자율주행 자동차를 깊이 신뢰하지 않고 운전에 집중을 가하여야 한다고 생각한다.
작자와 다른 의견을 가지는 사람이 있듯이 인공지능으로 인해 벌어지는 윤리적 문제에 대하여 누가 책임을 져야 하고, 어떻게 보상하여야 하는지에 대한 쟁점이 불같이 논의되고 있다. 인공지능과 함께 하는 사회의 구성원으로서 인공지능 윤리는 매우 중요하다. 신뢰성, 책임성, 편향성과 악용, 딜레마 등의 윤리적 쟁점에서 이런 윤리적 문제를 해결하기 위한 윤리적 기준은 국가, 문화, 시대별로 다르다. 그렇기에 윤리적 쟁점을 기술적으로 해결하는 것이 아닌 투명성, 공정성, 사회적 책임성을 바탕으로 사회적으로 논의하고 합의하여 사회 구성원 모두가 윤리 의식과 공정성에 대해 고민하고 해결하여야 한다. 인공지능과 관련하여 어떠한 문제가 발생하더라도 사회 구성원 모두가 책임을 지고 이롭게 이용될 수 있도록 인공지능 윤리가 정립되는 것은 중요하다.
 인공지능과 관련하여 사회적 문제 해결과 편향된 데이터를 줄이는 방법, 문제를 통한 인공지능 사회 구성원의 책임, 인공지능 윤리에 관하여 이야기를 나누었다. 현대사회와 미래사회에서의 인공지능의 역할이 올바르고 유익하게 사용될 수 있도록 인공지능에 관한 논점에 대해 모두가 이해하고, 인공지능 기술이 우리 사회에 더욱 이롭게 커졌으면 하는 바람으로 글을 마친다.